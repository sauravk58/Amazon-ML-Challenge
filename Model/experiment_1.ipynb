{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy torch torchvision transformers scikit-learn opencv-python pytesseract tqdm optuna joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torchvision import transforms\n",
    "import optuna\n",
    "\n",
    "# Mapping of entities to measurement units\n",
    "unit_mapping = {\n",
    "    'width': {'centimetre', 'inch', 'cm', 'mm', 'm'},\n",
    "    'height': {'centimetre', 'inch', 'cm', 'mm', 'm'},\n",
    "    'depth': {'centimetre', 'inch', 'cm', 'mm', 'm'},\n",
    "    'item_weight': {'gram', 'kilogram', 'ounce', 'pound', 'g', 'kg', 'lb', 'oz'},\n",
    "    'item_volume': {'millilitre', 'litre', 'ml', 'l'}\n",
    "}\n",
    "\n",
    "# Loading data from a CSV file\n",
    "def load_csv_data(file_path, sample_size=1000):\n",
    "    data_frame = pd.read_csv(file_path).sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "    return data_frame\n",
    "\n",
    "# Clean extracted entity_value by parsing out numbers and units\n",
    "def clean_value(value):\n",
    "    try:\n",
    "        value = str(value)\n",
    "        value = re.sub(r'^[^\\d.]+', '', value)\n",
    "        parts = value.split()\n",
    "        if len(parts) >= 2:\n",
    "            num_value = float(parts[0])\n",
    "            unit = ' '.join(parts[1:])\n",
    "            return f\"{num_value} {unit}\"\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Pre-processing the dataset to clean and filter valid entries\n",
    "def clean_dataset(df):\n",
    "    df['entity_value'] = df['entity_value'].apply(clean_value)\n",
    "    df = df.dropna(subset=['entity_value'])\n",
    "    return df\n",
    "\n",
    "# Text extraction using OCR\n",
    "def process_image(image_url):\n",
    "    try:\n",
    "        img_path = torch.hub.download_url_to_file(image_url, 'temp_image.jpg')\n",
    "        img = cv2.imread('temp_image.jpg')\n",
    "        if img is None:\n",
    "            print(f\"Unable to load image from {image_url}\")\n",
    "            return None, \"\"\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "        extracted_text = pytesseract.image_to_string(cv2.imread('temp_image.jpg'))\n",
    "        return img, extracted_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image processing for {image_url}: {e}\")\n",
    "        return None, \"\"\n",
    "\n",
    "# Custom Dataset class for loading entity extraction data\n",
    "class EntityDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_length=128):\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img, text = process_image(row['image_link'])\n",
    "        \n",
    "        if img is None:\n",
    "            img = torch.zeros((3, 224, 224))\n",
    "        \n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        entity_value = row['entity_value'].strip()\n",
    "        parts = entity_value.split()\n",
    "        value = float(parts[0]) if len(parts) >= 2 and parts[0].isdigit() else 0.0\n",
    "        unit = ' '.join(parts[1:]) if len(parts) >= 2 else ''\n",
    "\n",
    "        return {\n",
    "            'image': img,\n",
    "            'input_ids': encoded_text['input_ids'].flatten(),\n",
    "            'attention_mask': encoded_text['attention_mask'].flatten(),\n",
    "            'group_id': torch.tensor(row['group_id'], dtype=torch.long),\n",
    "            'entity_name': torch.tensor(row['entity_name'], dtype=torch.long),\n",
    "            'value': torch.tensor(value, dtype=torch.float),\n",
    "            'unit': unit\n",
    "        }\n",
    "    \n",
    "## Hybrid Model Architecture\n",
    "# Neural network model combining BERT and ResNet\n",
    "class EntityModel(nn.Module):\n",
    "    def __init__(self, group_count, entity_count, unit_count):\n",
    "        super(EntityModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(2048, 128)\n",
    "        \n",
    "        self.group_embed = nn.Embedding(group_count, 16)\n",
    "        self.entity_embed = nn.Embedding(entity_count, 16)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 + 768 + 16 + 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.value_out = nn.Linear(128, 1)\n",
    "        self.unit_out = nn.Linear(128, unit_count)\n",
    "        \n",
    "    def forward(self, img, input_ids, attention_mask, group, entity):\n",
    "        img_features = self.resnet(img)\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = bert_output.last_hidden_state[:, 0, :]\n",
    "        group_features = self.group_embed(group)\n",
    "        entity_features = self.entity_embed(entity)\n",
    "        \n",
    "        combined_features = torch.cat((img_features, text_features, group_features, entity_features), dim=1)\n",
    "        x = torch.relu(self.fc1(combined_features))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        value_prediction = self.value_out(x)\n",
    "        unit_prediction = self.unit_out(x)\n",
    "        return value_prediction, unit_prediction\n",
    "\n",
    "# function for hyperparameter tuning using Optuna\n",
    "def tune_hyperparameters(trial):\n",
    "\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EntityModel(num_group_ids, num_entity_names, num_units).to(device)\n",
    "    \n",
    "    loss_fn_value = nn.MSELoss()\n",
    "    loss_fn_unit = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "    \n",
    "    epochs = 3\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in train_loader:\n",
    "            img = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            group = batch['group_id'].to(device)\n",
    "            entity = batch['entity_name'].to(device)\n",
    "            value = batch['value'].to(device)\n",
    "            unit = torch.tensor([unit_mapping.get(u, 0) for u in batch['unit']], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            value_pred, unit_pred = model(img, input_ids, attention_mask, group, entity)\n",
    "            loss_value = loss_fn_value(value_pred.squeeze(), value)\n",
    "            loss_unit = loss_fn_unit(unit_pred, unit)\n",
    "            loss = loss_value + loss_unit\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                img = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                group = batch['group_id'].to(device)\n",
    "                entity = batch['entity_name'].to(device)\n",
    "                value = batch['value'].to(device)\n",
    "                unit = torch.tensor([unit_mapping.get(u, 0) for u in batch['unit']], dtype=torch.long).to(device)\n",
    "                \n",
    "                value_pred, unit_pred = model(img, input_ids, attention_mask, group, entity)\n",
    "                loss_value = loss_fn_value(value_pred.squeeze(), value)\n",
    "                loss_unit = loss_fn_unit(unit_pred, unit)\n",
    "                validation_loss += (loss_value + loss_unit).item()\n",
    "        \n",
    "        trial.report(validation_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return validation_loss\n",
    "\n",
    "# Main execution of code\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_df = load_csv_data('train.csv', sample_size=1000)\n",
    "    data_df = clean_dataset(data_df)\n",
    "\n",
    "    # Tokenizer setup\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Label encoding for categorical features\n",
    "    group_encoder = LabelEncoder()\n",
    "    entity_encoder = LabelEncoder()\n",
    "    data_df['group_id'] = group_encoder.fit_transform(data_df['group_id'])\n",
    "    data_df['entity_name'] = entity_encoder.fit_transform(data_df['entity_name'])\n",
    "    unit_encoder = LabelEncoder()\n",
    "    units = list(set([unit for sublist in unit_mapping.values() for unit in sublist]))\n",
    "    unit_encoder.fit(units)\n",
    "    \n",
    "    num_group_ids = len(group_encoder.classes_)\n",
    "    num_entity_names = len(entity_encoder.classes_)\n",
    "    num_units = len(unit_encoder.classes_)\n",
    "\n",
    "    train_df, val_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "    train_data = EntityDataset(train_df, tokenizer)\n",
    "    val_data = EntityDataset(val_df, tokenizer)\n",
    "    \n",
    "    # Optimizing model using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(tune_hyperparameters, n_trials=10)\n",
    "    \n",
    "    print(\"Best hyperparameters found:\", study.best_trial.params)\n",
    "\n",
    "    # Training final model with best hyperparameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EntityExtractionModel(num_group_ids, num_entity_names, num_units).to(device)\n",
    "\n",
    "    criterion_value = nn.MSELoss()\n",
    "    criterion_unit = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "\n",
    "    num_epochs = 500\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            img = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            group = batch['group_id'].to(device)\n",
    "            entity = batch['entity_name'].to(device)\n",
    "            value = batch['value'].to(device)\n",
    "            unit = torch.tensor([unit_encoder.get(u, 0) for u in batch['unit']], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            value_pred, unit_pred = model(img, input_ids, attention_mask, group, entity)\n",
    "            loss_value = criterion_value(value_pred.squeeze(), value)\n",
    "            loss_unit = criterion_unit(unit_pred, unit)\n",
    "            loss = loss_value + loss_unit\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'entity_extraction_model.pth')\n",
    "    print(\"Model saved as 'entity_extraction_model.pth'\")\n",
    "\n",
    "    # Save encoders and other necessary information\n",
    "    import joblib\n",
    "    joblib.dump(group_encoder, 'group_encoder.joblib')\n",
    "    joblib.dump(entity_encoder, 'entity_encoder.joblib')\n",
    "    joblib.dump(unit_encoder, 'unit_encoder.joblib')\n",
    "    print(\"Encoders saved\")\n",
    "\n",
    "    print(\"Training completed. You can now use the saved model for inference on test.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pytesseract\n",
    "from torchvision import transforms\n",
    "\n",
    "# Custom dataset class for processing test data\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_len=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        image_tensor, extracted_text = process_image(row['image_link'])\n",
    "\n",
    "        # Tokenize text data using BERT tokenizer\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            extracted_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image_tensor,\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'group_id': torch.tensor(row['group_id'], dtype=torch.long),\n",
    "            'entity_name': torch.tensor(row['entity_name'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# This is a Function used to encode unknown labels\n",
    "def handle_unknown_labels(encoder, label_list):\n",
    "    encoded_values = []\n",
    "    for label in label_list:\n",
    "        try:\n",
    "            encoded_values.append(encoder.transform([label])[0])\n",
    "        except ValueError:\n",
    "            encoded_values.append(-1)  # Assign -1 for unseen labels\n",
    "    return encoded_values\n",
    "\n",
    "# This is for Loading saved model and encoders\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EntityExtractionModel(num_group_ids, num_entity_names, num_units)\n",
    "model.load_state_dict(torch.load('entity_extraction_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load encoders using joblib\n",
    "group_encoder = joblib.load('group_encoder.joblib')\n",
    "entity_encoder = joblib.load('entity_encoder.joblib')\n",
    "unit_encoder = joblib.load('unit_encoder.joblib')\n",
    "unit_decoder = {v: k for k, v in unit_encoder.items()}\n",
    "\n",
    "# Load test dataset\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = test_data.sample(n=10, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Handle unknown group_id and entity_name in test data\n",
    "test_data['group_id'] = handle_unknown_labels(group_encoder, test_data['group_id'])\n",
    "test_data['entity_name'] = handle_unknown_labels(entity_encoder, test_data['entity_name'])\n",
    "\n",
    "# Prepare the tokenizer and dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "test_dataset = CustomTestDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Prediction function\n",
    "def generate_predictions(model, dataloader, device):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating predictions\"):\n",
    "            # Moving batch data to appropriate device\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            groups = batch['group_id'].to(device)\n",
    "            entities = batch['entity_name'].to(device)\n",
    "            \n",
    "            # Handle unknown labels by setting them to zero index\n",
    "            groups[groups == -1] = 0\n",
    "            entities[entities == -1] = 0\n",
    "            \n",
    "            # Model predictions for value and unit\n",
    "            predicted_value, predicted_unit = model(images, input_ids, attention_mask, groups, entities)\n",
    "            \n",
    "            # Processing predictions\n",
    "            predicted_value = predicted_value.squeeze().cpu().numpy()\n",
    "            predicted_unit = torch.argmax(predicted_unit, dim=1).cpu().numpy()\n",
    "\n",
    "            for value, unit in zip(predicted_value, predicted_unit):\n",
    "                results.append((value, unit_decoder[unit]))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Performing predictions\n",
    "prediction_results = generate_predictions(model, test_loader, device)\n",
    "\n",
    "# Adding predictions to the test dataframe\n",
    "test_data['predicted_value'] = [pred[0] for pred in prediction_results]\n",
    "test_data['predicted_unit'] = [pred[1] for pred in prediction_results]\n",
    "\n",
    "# Displaying predictions for each sample\n",
    "print(\"\\nTest Sample Predictions:\")\n",
    "for idx, row in test_data.iterrows():\n",
    "    print(f\"Sample {idx + 1}:\")\n",
    "    print(f\"  Group ID: {row['group_id']} (Unknown if -1)\")\n",
    "    print(f\"  Entity Name: {row['entity_name']} (Unknown if -1)\")\n",
    "    print(f\"  Predicted Value: {row['predicted_value']:.2f} {row['predicted_unit']}\")\n",
    "    print()\n",
    "\n",
    "# Saving the predictions to a CSV file\n",
    "test_data.to_csv('test_out.csv', index=False)\n",
    "print(\"Predictions have been saved to 'test_out.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
